1. Project Goal

Build a production-ready GenAI application that:

Accepts images of ingredients or text

Detects ingredients using a vision-capable LLM (Gemini)

Generates recipe recommendations via MCPs

Handles user preferences and conversation context

Demonstrates modern AI development workflows, structured outputs, observability, and guardrails

2. Key Design Decisions

LLM choice: Gemini (configurable via config.py and environment variables), default gemini-3-flash-preview.

Orchestrator: Stateful PydanticAI agent with:

Session-based memory (chat_id)

Max history configurable (default 3)

Clears history on new images

Decision logic for which tools to call

Guardrails enforcing recipe-only responses

Tools (MCPs):

Ingredient Detection MCP (custom): vision-only, stateless, called only when ingredients are unknown.

Recipe MCP (external): generates recipes, stateless, receives ingredients and user preferences.

Session & Memory: in-memory, short-lived, stores messages, ingredients, image context.

API Design: FastAPI, POST /recommend-recipes, supports image_url, image_base64, and optional chat_id.

Observability: Langfuse for tracing tool calls, latency, errors, and simple evaluations.

CLI Tool: simple shell script to test API with local images.

Testing: Unit tests (schemas, guardrails, memory), integration tests with Langfuse and sample images.

Security & Config: No hard-coded secrets, configuration via environment variables.

3. Goals & Success Criteria

Demonstrate practical GenAI orchestration with structured outputs

Show tool integration with MCP

Provide traceable, auditable results

Ensure maintainable, modular, production-ready code

Clear and concise API and response contracts

Ability for reviewers or coding agents to run, test, and extend the system easily

4. High-Level Design
Components

CLI Script: sends images to API

FastAPI Service: HTTP layer, input validation, calls orchestrator

Orchestrator: central intelligence (PydanticAI agent)

Ingredient MCP: detects ingredients from image

Recipe MCP: returns recipes

Memory Store: stores chat context, ingredients, images

Langfuse: observability, evaluation

Data Flow

```mermaid
flowchart TD
CLI --> API
API --> ORCH
ORCH --> MEM
ORCH --> ING_MCP
ORCH --> REC_MCP
ORCH --> LF
```

Decision flow: Orchestrator checks guardrails → text ingredients → image → history → calls MCPs → returns response.

5. Pydantic Models

Ingredient: name, optional confidence

Recipe: title, description, ingredients, optional suitability_notes

ImageContext: image_id, description, image_base64

Request: chat_id, user_message, image_url, image_base64

Response: chat_id, ingredients, recipes, metadata (tools called, model, latency)

6. Tasks / Implementation Steps

Copilot instructions: first document for AI assistance.

Configuration: config.py for model selection, memory limit, Langfuse keys.

FastAPI API: input validation, session management, orchestrator call, structured response.

Orchestrator (PydanticAI):

Guardrails

Decision logic for MCP calls

Memory management (chat, history, images)

Crafting grounded responses

Ingredient Detection MCP: FastMCP server, stateless, returns structured ingredients.

Recipe MCP Integration: stateless, receives ingredients + preferences, returns recipes.

Memory Layer: in-memory session store with max history, image clearing, image description generation.

CLI Tool: reads images from folder, encodes, sends requests, prints responses.

Observability: Langfuse integration for traces and simple evaluation metrics.

Tests: unit tests for schemas, guardrails, memory; integration tests using sample images and Langfuse.

Documentation: README, PRD, Solution Design Document, Copilot instructions.

7. Non-Functional Considerations

Reliability: retries on schema validation, graceful failures

Maintainability: modular code, clear separation of concerns

Performance: avoid redundant MCP calls, measure latency

Security: no secrets in code, no raw image logging

Extensibility: easily add MCPs, modalities, or persistence layer in the future